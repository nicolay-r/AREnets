{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLCtJW2pbxaIZWJYduiK7/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolay-r/AREnets/blob/master/arenets_colab_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AREnets colab quick start tutorial\n",
        "\n",
        "## Setup Python 3.6.9 Environment\n",
        "In this section we setup `python-3.6` requireed by tensorflow version `1.14.0`"
      ],
      "metadata": {
        "id": "GFtrYfHLn9Gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo update-alternatives --config python3"
      ],
      "metadata": {
        "id": "X1xBsoiNyPBu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca17389f-ce10-4c0e-caf7-2b7a106d0859"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 choices for the alternative python3 (providing /usr/bin/python3).\n",
            "\n",
            "  Selection    Path                Priority   Status\n",
            "------------------------------------------------------------\n",
            "* 0            /usr/bin/python3.8   2         auto mode\n",
            "  1            /usr/bin/python3.6   1         manual mode\n",
            "  2            /usr/bin/python3.8   2         manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: 1\n",
            "update-alternatives: using /usr/bin/python3.6 to provide /usr/bin/python3 (python3) in manual mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://bootstrap.pypa.io/pip/3.6/get-pip.py\n",
        "!sudo python get-pip.py"
      ],
      "metadata": {
        "id": "OJ0LVVh60Ej2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCNEJNTr1JzN"
      },
      "outputs": [],
      "source": [
        "!sudo pip uninstall arenets\n",
        "!sudo pip install git+https://github.com/nicolay-r/AREnets@master"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the code\n"
      ],
      "metadata": {
        "id": "ZzIIjAUslZbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content\"\n",
        "# clear prior local versions\n",
        "!rm ./*.py*\n",
        "!wget https://raw.githubusercontent.com/nicolay-r/AREnets/master/tutorials/nn_config.py\n",
        "!wget https://raw.githubusercontent.com/nicolay-r/AREnets/master/tutorials/predict.py\n",
        "!wget https://raw.githubusercontent.com/nicolay-r/AREnets/master/tutorials/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Tf9DjBQziNp",
        "outputId": "0aa9a5bb-b0e7-42d4-ad73-b1fac41b0680"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "rm: cannot remove './*.py*': No such file or directory\n",
            "--2023-01-03 22:09:55--  https://raw.githubusercontent.com/nicolay-r/AREnets/master/tutorials/nn_config.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 417 [text/plain]\n",
            "Saving to: ‘nn_config.py’\n",
            "\n",
            "nn_config.py        100%[===================>]     417  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-03 22:09:55 (25.6 MB/s) - ‘nn_config.py’ saved [417/417]\n",
            "\n",
            "--2023-01-03 22:09:55--  https://raw.githubusercontent.com/nicolay-r/AREnets/master/tutorials/predict.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 439 [text/plain]\n",
            "Saving to: ‘predict.py’\n",
            "\n",
            "predict.py          100%[===================>]     439  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-03 22:09:55 (26.8 MB/s) - ‘predict.py’ saved [439/439]\n",
            "\n",
            "--2023-01-03 22:09:55--  https://raw.githubusercontent.com/nicolay-r/AREnets/master/tutorials/train.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1039 (1.0K) [text/plain]\n",
            "Saving to: ‘train.py’\n",
            "\n",
            "train.py            100%[===================>]   1.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-03 22:09:55 (63.5 MB/s) - ‘train.py’ saved [1039/1039]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download input samples"
      ],
      "metadata": {
        "id": "5DFxruKEn9fs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/_data\"\n",
        "!rm *.jsonl*\n",
        "!rm *.tsv.gz*\n",
        "!wget https://raw.githubusercontent.com/nicolay-r/AREnets/master/tutorials/_data/sample-train.tsv.gz\n",
        "!wget https://raw.githubusercontent.com/nicolay-r/AREnets/master/tutorials/_data/sample-test.tsv.gz\n",
        "!wget https://raw.githubusercontent.com/nicolay-r/AREnets/master/tutorials/_data/sample-train.jsonl\n",
        "!wget https://raw.githubusercontent.com/nicolay-r/AREnets/master/tutorials/_data/sample-test.jsonl"
      ],
      "metadata": {
        "id": "_KMYt-B7oAf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare embedding\n",
        "You can choose your one from the [following resource](http://vectors.nlpl.eu/repository/20/6.zip) for mostly any language you want."
      ],
      "metadata": {
        "id": "ia0ufIsKmw4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://vectors.nlpl.eu/repository/20/6.zip -P \"_data\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrg-nobCmzEx",
        "outputId": "1c7de410-8285-4955-a7b9-9681bb48300c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-03 21:50:10--  http://vectors.nlpl.eu/repository/20/6.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.181\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.181|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 635351287 (606M) [application/zip]\n",
            "Saving to: ‘_data/6.zip’\n",
            "\n",
            "6.zip               100%[===================>] 605.92M  17.3MB/s    in 84s     \n",
            "\n",
            "2023-01-03 21:51:35 (7.23 MB/s) - ‘_data/6.zip’ saved [635351287/635351287]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/_data\"\n",
        "!unzip *.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9eszW-Kntlu",
        "outputId": "ecbf8cd6-063c-464d-eaae-f228a3bec425"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/_data\n",
            "Archive:  6.zip\n",
            "  inflating: meta.json               \n",
            "  inflating: model.bin               \n",
            "  inflating: model.txt               \n",
            "  inflating: README                  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "Please, use files in order to open up `train.py` and customize training script for your needs."
      ],
      "metadata": {
        "id": "8pL6nnKeleez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content\"\n",
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91CTslwoz-_W",
        "outputId": "fdb0bc8d-8006-4580-acb8-0335b95759e7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:arenets.arekit.contrib.utils.io_utils.utils:Check existence [True]: _data/vocab.txt\n",
            "INFO:arenets.arekit.contrib.utils.io_utils.utils:Check existence [True]: _data/term_embedding.npz\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/arenets/context/configurations/base/base.py:190: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/arenets/context/configurations/base/base.py:190: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:arenets.arekit.contrib.utils.io_utils.utils:Check existence [True]: _data/sample-train.jsonl\n",
            "INFO:arenets.arekit.contrib.utils.io_utils.utils:Check existence [True]: _data/vocab.txt\n",
            "INFO:arenets.arekit.contrib.utils.io_utils.utils:Check existence [True]: _data/term_embedding.npz\n",
            "INFO:arenets.arekit.contrib.utils.np_utils.embedding:Embedding read [size=(302866, 300)]: _data/term_embedding.npz\n",
            "INFO:arenets.arekit.contrib.utils.np_utils.vocab:Loading vocabulary [size=302866]: _data/vocab.txt\n",
            "Filling bags collection [DataType.Train]: 0it [00:00, ?it/s]Traceback (most recent call last):\n",
            "  File \"train.py\", line 27, in <module>\n",
            "    unknown_term_index=0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/arenets/quickstart/train.py\", line 109, in train\n",
            "    \"data_type\": DataType.Train})\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/arenets/arekit/common/pipeline/base.py\", line 18, in run\n",
            "    input_data = item.apply(input_data=input_data, pipeline_ctx=pipeline_ctx)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/arenets/arekit/common/pipeline/items/base.py\", line 11, in apply\n",
            "    output_data = self.apply_core(input_data=input_data, pipeline_ctx=pipeline_ctx)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/arenets/pipelines/items/training.py\", line 170, in apply_core\n",
            "    data_type=data_type if data_type is not None else DataType.Train)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/arenets/pipelines/items/training.py\", line 121, in __handle_iteration\n",
            "    bag_size=self.__config.BagSize)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/arenets/core/ctx_inference.py\", line 74, in initialize\n",
            "    unknown_term_index=unknown_term_index)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/arenets/core/ctx_inference.py\", line 110, in __read_for_data_type\n",
            "    create_sample_func=lambda row: InputSample.create_from_parameters(\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/arenets/core/feeding/bags/collection/base.py\", line 47, in from_formatted_samples\n",
            "    create_empty_sample_func=create_empty_sample_func)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/arenets/core/feeding/bags/collection/single.py\", line 30, in _fill_bags_list_with_linked_text_opinions\n",
            "    s = create_sample_func(parsed_row)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/arenets/core/ctx_inference.py\", line 124, in <lambda>\n",
            "    unknown_term_index=unknown_term_index))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/arenets/sample.py\", line 211, in create_from_parameters\n",
            "    assert(len(terms) == len(pos_tags))\n",
            "AssertionError\n",
            "Filling bags collection [DataType.Train]: 0it [00:00, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict\n",
        "\n",
        "Please, use files in order to open up `predict.py` and customize prediction script for your needs.\n"
      ],
      "metadata": {
        "id": "jwPyLMzPmZlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content\"\n",
        "!python predict.py"
      ],
      "metadata": {
        "id": "AtDHlgDv0CHe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}